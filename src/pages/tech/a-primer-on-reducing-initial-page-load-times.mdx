export const meta = {
  date: '2021-08-02T02:26:39.357Z',
  title: 'A primer on reducing initial page load times',
  description: 'Learn how to speed up your website and keep users happy.',
};

### TLDR

To achieve the fastest initial page load:

- Use a static page served through a CDN.
- Preload resources and preconnect to external origins.
- Use cookies and injected scripts to speed up redirects.

<div className="border-b"></div>

One thing I've always obsessed over when visiting any online dashboard, is how fast everything loads.
Particularly if I'm visiting an authenticated route. You just have to sit there and watch spinners spin,
and feint gray boxes pulse while it tries to work out if you're authenticated,
if it should redirect you to sign in, or if it should
finally start loading some data - and then show you even more spinners.

Nobody likes waiting, so I wanted to share some of the strategies I'm using at [univo](https://univo.app) to reduce initial
page load times and keep users happy.

Currently, the dashboard loads like this:

It's fast.

If you don't believe that gif, try for yourself. [Sign up](https://univo.app/register), enter a random store name,
close your tab, and then click this [https://univo.app](https://univo.app) to navigate to the homepage.

## The request

Before we do anything, we first need to understand what happens from the moment a user hits enter in their search bar until the moment
the dashboard is fully loaded. In this way, we'll better understand what parts of the request we can optimize.

A good way of understanding this process is by starting with a checklist of things that need to be done when the user requests our dashboard. We'll use
these as the building blocks for the request.

1. Serve the user the HTML, JS, and CSS for that page.
2. Determine if they are authenticated or not.
3. Load the user-specific data for that page.

## Static pages are fast

The first optimisation is about reducing a metric known as Time to First Byte (TTFB). Basically, it's how long it takes the
browser to receive a response from a server for the requested resource. There are two simple methods of reducing your TTFB:

1. Reduce how long it takes your server to generate the requested resource.
2. Reduce how far (geographically) the request has to travel.

There are several ways we can reduce the time taken to generate the page on the server like having more CPU power, avoiding
HTTP requests, speeding up database queries, etc. However, the fastest computation is always going to be no computation at all.

If the requested resource is a static asset, i.e. it doesn't change regardless of the request parameters, the server can just
send that back to the browser every time without having to think.

So in terms of performance, serving a static `.html` file is a no-brainer. Of course, prioritising performance like this
is a trade off for arguably a worse developer/user experience in certain ways, but that debate is outside the scope of this article.
Just remember, it's important to weigh up whether performance is something you want in your use case.

One thing that static assets also enable is the opportunity to minimise the distance the request has to travel.
When you request [univo](https://univo.app), you're sending a request to a server in Sydney, Australia. So if you're
currently sitting in a bedroom in the North Pole, that's a lot of kilometres for your request to travel through cables.
It would be great if we could put a server geographically in the middle of that path, maybe somewhere in Singapore.
Even better if we could put a server in your neighbours house.

With static assets, we actually can because we know that the response is going to be the same (the asset itself)
regardless of changes in the request parameters. This is known as
a Content Delivery Network (CDN). Basically, a server just watches requests go by and saves a copy of the response, so that
if any identical subsequent requests occur, it can step in and send that cached response straight back.

When I deploy [univo](https://univo.app) to [Vercel](https://vercel.com), that's exactly
what their [edge network](https://vercel.com/docs/edge-network/overview) is doing.

## Preload and preconnect

Once the browser recieves the page, how can we speed up inevitable subsequent requests for different fonts, css files, and
requests for data? By preloading and preconnecting to those resources. Right now on this blog, open up your browsers devtools, click on
the "Elements" tab, and open up the `<head>` tag. The very next tag you should see should be something like:

```jsx
<link rel="preload" href="/fonts/inter-var-latin.woff2" as="font" />
```

Since we know that we are about to load and use the [Inter](https://rsms.me/inter/) font, why not tell the browser as soon as possible?
That's exactly what this tag is doing. In that way, by the time the browser parses the CSS rule that actually enforces the font,
it might already be loaded and ready to go.

If you scroll down some more in the `<head>`, you'll notice even more tags like that of a similar nature for loading css files, scripts, and more.
If you know you'll be loading resources straight away like this, giving the browser warning is a great way of speeding that process up.

Preconnecting is practically the same, but is used when those resources sit on an external domain. On the [univo](https://univo.app) dashboard
we preconnect to our external API, so when it comes time to fetch data for the user that connection is open and raring to go.

## Using a cookie to speed up redirects

All of these optimisations are great, but in the scenario when a user lands on the wrong page, the most performant thing we can do
is redirect them as fast as possible. A great example of this is an unauthenticated user lands on the dashboard and needs to be redirected
to sign in.

As a consequence of our decision to make the page static, we can only perform this redirect on the client.
